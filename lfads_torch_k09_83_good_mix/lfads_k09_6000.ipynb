{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAN Workshop- LFADS demo in pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "np = torch._np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "from lfads import LFADS_Net\n",
    "from utils import read_data, load_parameters, save_parameters\n",
    "import scipy.io\n",
    "# plt.style.use('dark_background')\n",
    "import shutil\n",
    "path = './models'\n",
    "if os.path.isdir(path): \n",
    "    shutil.rmtree(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Select device to train LFADS on\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'; print('Using device: %s'%device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load or Generate Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_time =12000\n",
    "start_time = 2000\n",
    "Time = 30\n",
    "neuron_num = 71\n",
    "datax = scipy.io.loadmat(\"spike71_k09_26000.mat\")\n",
    "y_data = datax[\"spike71_k09_26000\"][:,start_time:all_time].T\n",
    "traj = scipy.io.loadmat(\"trj71_k09_26000.mat\")\n",
    "traj = traj[\"trj71_k09_26000\"][:,start_time:all_time].T\n",
    "NRep=int((all_time-start_time)/Time)\n",
    "output = np.zeros((NRep,Time,neuron_num))\n",
    "print(y_data.shape)\n",
    "for i in range(all_time-start_time):\n",
    "    for j in range(neuron_num):\n",
    "        if y_data[i][j] > 25:\n",
    "            y_data[i][j] = 25\n",
    "for i in range(NRep):\n",
    "    output[i,:,:] = y_data[Time*i:Time*(i+1),:]\n",
    "output = output.astype('float32')\n",
    "output = torch.Tensor(output).to(device)\n",
    "print(output.shape)\n",
    "output_valid = output.detach().clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View example Ground Truth Firing Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds      = torch.utils.data.TensorDataset(output)\n",
    "valid_ds      = torch.utils.data.TensorDataset(output)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(traj[:,0],traj[:,1])\n",
    "plt.figure(figsize=(4, 4))\n",
    "ax1 = plt.subplot(311)\n",
    "ax1.plot(traj[:, 0], lw=4, color='k')\n",
    "\n",
    "ax2 = plt.subplot(312, sharex=ax1)\n",
    "ax2.plot(traj[:, 1], lw=4, color='k')    \n",
    "\n",
    "# Z score output:\n",
    "output=output.reshape(Time*NRep,neuron_num)\n",
    "from scipy import stats\n",
    "output = stats.zscore(output,axis=0)\n",
    "output = output.reshape(NRep,Time,neuron_num)\n",
    "print(output[0].shape)\n",
    "plt.figure(figsize = (12,12))\n",
    "plt.imshow(y_data.T, cmap=plt.cm.plasma,aspect='auto')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Cell #')\n",
    "plt.colorbar(orientation='horizontal', label='Firing Rate (Hz)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(neuron_num):\n",
    "    fig, ax = plt.subplots()\n",
    "    mappable = ax.scatter(traj[:,0], traj[:,1], c=y_data[:,i] ,cmap='coolwarm',vmin=0,vmax=8,s=1)\n",
    "    fig.colorbar(mappable)\n",
    "    plt.title(i+1)\n",
    "    plt.show()\n",
    "#fig.savefig(\"img.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LFADS Schema\n",
    "<img src='lfads_schema.png' width=800 align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'chaotic_rnn',\n",
       " 'run_name': 'demo',\n",
       " 'g_dim': 20,\n",
       " 'u_dim': 20,\n",
       " 'factors_dim': 2,\n",
       " 'g0_encoder_dim': 20,\n",
       " 'c_encoder_dim': 20,\n",
       " 'controller_dim': 20,\n",
       " 'g0_prior_kappa': 0.1,\n",
       " 'u_prior_kappa': 0.1,\n",
       " 'keep_prob': 0.95,\n",
       " 'clip_val': 5.0,\n",
       " 'max_norm': 200,\n",
       " 'learning_rate': 0.015,\n",
       " 'learning_rate_min': 1e-05,\n",
       " 'learning_rate_decay': 0.95,\n",
       " 'scheduler_on': True,\n",
       " 'scheduler_patience': 6,\n",
       " 'scheduler_cooldown': 6,\n",
       " 'kl_weight_schedule_start': 0,\n",
       " 'kl_weight_schedule_dur': 2000,\n",
       " 'l2_weight_schedule_start': 0,\n",
       " 'l2_weight_schedule_dur': 2000,\n",
       " 'epsilon': 0.1,\n",
       " 'betas': (0.9, 0.99),\n",
       " 'l2_gen_scale': 2000,\n",
       " 'l2_con_scale': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams = load_parameters('./parameters.yaml')\n",
    "save_parameters(hyperparams)\n",
    "hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate LFADS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed: 6583\n"
     ]
    }
   ],
   "source": [
    "model = LFADS_Net(inputs_dim = neuron_num, T = Time, dt = 1, device=device,\n",
    "                 model_hyperparams=hyperparams).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick up where you left off (if you have a recent save) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"tt = np.empty((3000,2))\\nfor k in range(10):\\n    t = model.infer_trj(output_valid[batch_size *k:batch_size *(k+1),:])\\n    #print(t[90].shape)\\n    for i in range(batch_size):\\n        for j in range(100):\\n            tt[k*100*i+j,:]=t[j][i].to('cpu').detach().numpy().copy()\\nplt.figure()\\nplt.plot(tt)\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_checkpoint('recent')\n",
    "batch_size = 3\n",
    "\"\"\"tt = np.empty((3000,2))\n",
    "for k in range(10):\n",
    "    t = model.infer_trj(output_valid[batch_size *k:batch_size *(k+1),:])\n",
    "    #print(t[90].shape)\n",
    "    for i in range(batch_size):\n",
    "        for j in range(100):\n",
    "            tt[k*100*i+j,:]=t[j][i].to('cpu').detach().numpy().copy()\n",
    "plt.figure()\n",
    "plt.plot(tt)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model\n",
    "\n",
    "Rule of thumb: You can usually see good fit after 200 epochs (~30 mins runtime on Thinkpad GPU, ~2.5 hours on CPU), but to see good inference of perturbation timings need to run for about 800 epochs (~2 hours on Thinkpad GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training...\n",
      "Epoch:    1, Step:   111, training loss: 2620.159\n",
      "recon: 3079, kl:   193, dir:    0, klw:   0\n",
      "Epoch:    2, Step:   222, training loss: 2464.798\n",
      "recon: 2893, kl:   367, dir:    2, klw:   0\n",
      "Epoch:    3, Step:   333, training loss: 2426.019\n",
      "recon: 2612, kl:   544, dir:    1, klw:   0\n",
      "Epoch:    4, Step:   444, training loss: 2397.630\n",
      "recon: 2745, kl:   597, dir:    1, klw:   0\n",
      "Epoch:    5, Step:   555, training loss: 2379.417\n",
      "recon: 2119, kl:   703, dir:    0, klw:   0\n",
      "Epoch:    6, Step:   666, training loss: 2328.338\n",
      "recon: 2550, kl:   883, dir:    4, klw:   0\n",
      "Epoch:    7, Step:   777, training loss: 2309.886\n",
      "recon: 2091, kl:  1405, dir:    2, klw:   0\n",
      "Epoch:    8, Step:   888, training loss: 2288.126\n",
      "recon: 2718, kl:  1303, dir:    0, klw:   0\n",
      "Epoch:    9, Step:   999, training loss: 2280.330\n",
      "recon: 2662, kl:  1836, dir:    0, klw:   0\n",
      "Epoch:   10, Step:  1110, training loss: 2266.379\n",
      "recon: 2269, kl:  2012, dir:    5, klw:   0\n",
      "Epoch:   11, Step:  1221, training loss: 2270.428\n",
      "recon: 2048, kl:  1979, dir:    0, klw:   0\n",
      "Epoch:   12, Step:  1332, training loss: 2256.810\n",
      "recon: 2387, kl:  2537, dir:    6, klw:   0\n",
      "Epoch:   13, Step:  1443, training loss: 2250.627\n",
      "recon: 2403, kl:  2557, dir:    8, klw:   0\n",
      "Epoch:   14, Step:  1554, training loss: 2246.567\n",
      "recon: 2438, kl:  3706, dir:   36, klw:   0\n",
      "Epoch:   15, Step:  1665, training loss: 2251.816\n",
      "recon: 2326, kl:  3804, dir:    1, klw:   0\n",
      "Epoch:   16, Step:  1776, training loss: 2236.166\n",
      "recon: 2053, kl:  4304, dir:    1, klw:   0\n",
      "Epoch:   17, Step:  1887, training loss: 2234.986\n",
      "recon: 1834, kl:  3798, dir:    2, klw:   0\n",
      "Epoch:   18, Step:  1998, training loss: 2227.793\n",
      "recon: 2294, kl:  4762, dir:    1, klw:   0\n",
      "Epoch:   19, Step:  2109, training loss: 2225.646\n",
      "recon: 2159, kl:  4244, dir:    4, klw:   1\n",
      "Epoch:   20, Step:  2220, training loss: 2222.993\n",
      "recon: 2267, kl:  4417, dir:    2, klw:   1\n",
      "Epoch:   21, Step:  2331, training loss: 2225.824\n",
      "recon: 2427, kl:  5032, dir:    1, klw:   1\n",
      "Epoch:   22, Step:  2442, training loss: 2227.698\n",
      "recon: 2591, kl:  6125, dir:    4, klw:   1\n",
      "Epoch:   23, Step:  2553, training loss: 2227.527\n",
      "recon: 2260, kl:  4595, dir:    0, klw:   1\n",
      "Epoch:   24, Step:  2664, training loss: 2226.320\n",
      "recon: 2210, kl:  4880, dir:    1, klw:   1\n",
      "Epoch:   25, Step:  2775, training loss: 2214.902\n",
      "recon: 2524, kl:  5932, dir:    2, klw:   1\n",
      "Epoch:   26, Step:  2886, training loss: 2220.111\n",
      "recon: 2272, kl:  7107, dir:    7, klw:   1\n",
      "Epoch:   27, Step:  2997, training loss: 2221.718\n",
      "recon: 1877, kl:  5327, dir:    2, klw:   1\n",
      "Epoch:   28, Step:  3108, training loss: 2231.846\n",
      "recon: 2469, kl:  6066, dir:   36, klw:   1\n",
      "Learning rate decreased to 0.01425000\n",
      "Epoch:   29, Step:  3219, training loss: 2221.105\n",
      "recon: 2170, kl:  5592, dir:    1, klw:   1\n",
      "Epoch:   30, Step:  3330, training loss: 2211.485\n",
      "recon: 2236, kl:  6063, dir:    2, klw:   1\n",
      "Epoch:   31, Step:  3441, training loss: 2211.850\n",
      "recon: 2130, kl:  5545, dir:   11, klw:   1\n",
      "Epoch:   32, Step:  3552, training loss: 2228.008\n",
      "recon: 1869, kl:  6371, dir:    0, klw:   1\n",
      "Epoch:   33, Step:  3663, training loss: 2218.829\n",
      "recon: 2477, kl:  6750, dir:    8, klw:   1\n",
      "Epoch:   34, Step:  3774, training loss: 2222.999\n",
      "recon: 1962, kl:  5644, dir:    3, klw:   1\n",
      "Epoch:   35, Step:  3885, training loss: 2211.976\n",
      "recon: 2626, kl:  6480, dir:    1, klw:   1\n",
      "Epoch:   36, Step:  3996, training loss: 2220.336\n",
      "recon: 2008, kl:  6374, dir:    2, klw:   1\n",
      "Epoch:   37, Step:  4107, training loss: 2217.369\n",
      "recon: 2131, kl:  8764, dir:   16, klw:   1\n",
      "Epoch:   38, Step:  4218, training loss: 2208.230\n",
      "recon: 2360, kl:  7566, dir:    0, klw:   1\n",
      "Epoch:   39, Step:  4329, training loss: 2196.974\n",
      "recon: 1901, kl:  8151, dir:    1, klw:   1\n",
      "Epoch:   40, Step:  4440, training loss: 2202.965\n",
      "recon: 2299, kl:  5387, dir:    0, klw:   1\n",
      "Epoch:   41, Step:  4551, training loss: 2198.222\n",
      "recon: 1861, kl:  7628, dir:    1, klw:   1\n",
      "Epoch:   42, Step:  4662, training loss: 2205.774\n",
      "recon: 2334, kl:  9753, dir:    1, klw:   1\n",
      "Epoch:   43, Step:  4773, training loss: 2207.512\n",
      "recon: 2399, kl:  8577, dir:    1, klw:   1\n",
      "Epoch:   44, Step:  4884, training loss: 2215.637\n",
      "recon: 2354, kl:  9626, dir:    1, klw:   1\n",
      "Learning rate decreased to 0.01353750\n",
      "Epoch:   45, Step:  4995, training loss: 2208.432\n",
      "recon: 2316, kl:  8341, dir:    6, klw:   1\n",
      "Epoch:   46, Step:  5106, training loss: 2200.994\n",
      "recon: 2544, kl:  7151, dir:    2, klw:   1\n",
      "Epoch:   47, Step:  5217, training loss: 2192.824\n",
      "recon: 2305, kl:  9943, dir:    4, klw:   1\n",
      "Epoch:   48, Step:  5328, training loss: 2201.190\n",
      "recon: 2147, kl:  6770, dir:    1, klw:   1\n",
      "Epoch:   49, Step:  5439, training loss: 2199.442\n",
      "recon: 1901, kl:  8079, dir:    0, klw:   1\n",
      "Epoch:   50, Step:  5550, training loss: 2203.317\n",
      "recon: 2390, kl:  6812, dir:    1, klw:   1\n",
      "Epoch:   51, Step:  5661, training loss: 2201.011\n",
      "recon: 2412, kl:  7455, dir:    2, klw:   1\n",
      "Epoch:   52, Step:  5772, training loss: 2208.125\n",
      "recon: 2116, kl:  7457, dir:    3, klw:   1\n",
      "Learning rate decreased to 0.01286062\n",
      "Epoch:   53, Step:  5883, training loss: 2204.565\n",
      "recon: 2539, kl:  8412, dir:    1, klw:   1\n",
      "Epoch:   54, Step:  5994, training loss: 2204.115\n",
      "recon: 1959, kl:  5947, dir:    0, klw:   1\n",
      "Epoch:   55, Step:  6105, training loss: 2193.547\n",
      "recon: 2060, kl:  6989, dir:    1, klw:   1\n",
      "Epoch:   56, Step:  6216, training loss: 2206.252\n",
      "recon: 2310, kl:  7232, dir:    0, klw:   1\n",
      "Epoch:   57, Step:  6327, training loss: 2193.909\n",
      "recon: 2582, kl:  7126, dir:    1, klw:   1\n",
      "Epoch:   58, Step:  6438, training loss: 2201.973\n",
      "recon: 2274, kl:  9106, dir:    1, klw:   1\n",
      "Epoch:   59, Step:  6549, training loss: 2201.020\n",
      "recon: 1800, kl:  8296, dir:    0, klw:   1\n",
      "Epoch:   60, Step:  6660, training loss: 2193.635\n",
      "recon: 2366, kl:  7616, dir:    2, klw:   1\n",
      "Epoch:   61, Step:  6771, training loss: 2195.784\n",
      "recon: 2199, kl:  8352, dir:    0, klw:   1\n",
      "Epoch:   62, Step:  6882, training loss: 2194.752\n",
      "recon: 2105, kl:  7490, dir:    1, klw:   1\n",
      "Epoch:   63, Step:  6993, training loss: 2190.084\n",
      "recon: 2240, kl:  7306, dir:    1, klw:   1\n",
      "Epoch:   64, Step:  7104, training loss: 2190.367\n",
      "recon: 2120, kl:  6014, dir:    0, klw:   1\n",
      "Epoch:   65, Step:  7215, training loss: 2196.656\n",
      "recon: 2032, kl:  7995, dir:    0, klw:   1\n",
      "Epoch:   66, Step:  7326, training loss: 2193.414\n",
      "recon: 2068, kl:  7783, dir:    0, klw:   1\n",
      "Epoch:   67, Step:  7437, training loss: 2192.711\n",
      "recon: 2432, kl:  9457, dir:    9, klw:   1\n",
      "Epoch:   68, Step:  7548, training loss: 2193.856\n",
      "recon: 1951, kl:  6724, dir:    1, klw:   1\n",
      "Epoch:   69, Step:  7659, training loss: 2193.230\n",
      "recon: 1818, kl:  7778, dir:    0, klw:   1\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_ds, valid_ds, max_epochs=800, batch_size=batch_size , use_tensorboard=False,\n",
    "          train_truth=train_ds, valid_truth=valid_ds) #4270"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load checkpoint with lowest validation error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_checkpoint('best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(output_valid.shape)\n",
    "#model.plot_factors()\n",
    "tt = np.zeros(((all_time-start_time),2))\n",
    "sp = np.zeros(((all_time-start_time),neuron_num))\n",
    "batch_size=1\n",
    "gg = int(NRep/batch_size)\n",
    "for k in range(gg):\n",
    "    t = model.infer_factors(output_valid[batch_size *k:batch_size *(k+1),:])\n",
    "    #spi = model.reconstruct(output_valid[batch_size *k:batch_size *(k+1),:])\n",
    "    #print(spi.shape)\n",
    "    for i in range(batch_size):\n",
    "        for j in range(Time):\n",
    "            tt[(i+batch_size*k)*Time+j,:] = t[i][j].to('cpu').detach().numpy().copy()\n",
    "            #for l in range(neuron_num):\n",
    "                #sp[(i+batch_size*k)*Time+j,l] = spi[j][l]\n",
    "plt.figure()\n",
    "plt.plot(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(neuron_num):\n",
    "    plt.figure()\n",
    "    plt.plot(y_data[:,i], linewidth = 2)\n",
    "    plt.plot(sp[:,i],'r',linewidth = 1)\n",
    "    plt.title(i)\n",
    "    plt.ylim(-2,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import funs\n",
    "qz_mean_est = tt\n",
    "#plt.plot(qz_mean_est[:,0])\n",
    "qz_est_norm = qz_mean_est#np.stack(qz_mean_est)/np.linalg.norm(np.stack(qz_mean_est))\n",
    "#plt.plot(qz_est_norm[:,0],qz_est_norm[:,1])\n",
    "z_true_c = traj# - x_test.mean(axis=0)\n",
    "z_true_norm = z_true_c#/np.linalg.norm(z_true_c)\n",
    "\n",
    "R = funs.compute_optimal_rotation(np.stack(qz_est_norm), z_true_norm, scale=True)\n",
    "qz_est_norm_R = np.stack(qz_est_norm).dot(R)\n",
    "\n",
    "from scipy import signal\n",
    "qz_est_norm_R[:,0] = signal.savgol_filter(qz_est_norm_R[:,0], 51, 5)\n",
    "qz_est_norm_R[:,1] = signal.savgol_filter(qz_est_norm_R[:,1],51, 5)\n",
    "st=0\n",
    "en=4000\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.subplot(211)\n",
    "plt_post = plt.plot(qz_est_norm_R[st:en,0],'r', linewidth = 1, label = 'posterior mean')\n",
    "plt_true = plt.plot(z_true_norm[st:en,0], 'k', linewidth = 1, label = '\\\"true\\\" mean')\n",
    "plt.subplot(212)\n",
    "plt_post = plt.plot(qz_est_norm_R[st:en,1],'r', linewidth = 1, label = 'posterior mean')\n",
    "plt_true = plt.plot(z_true_norm[st:en,1], 'k', linewidth = 1, label = '\\\"true\\\" mean')\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.plot(z_true_norm[st:en,0], z_true_norm[st:en,1], lw=2, color = 'k')\n",
    "plt.plot(qz_est_norm_R[st:en,0], qz_est_norm_R[st:en,1], lw=2, color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt('lfads_k09_L.csv', qz_est_norm_R, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_lfads_torch)",
   "language": "python",
   "name": "conda_lfads_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
